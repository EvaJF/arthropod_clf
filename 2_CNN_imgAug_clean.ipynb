{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arthropod Classification with a simple CNN\n",
    "\n",
    "The goal of this notebook is to train a first version of our arthropods classification. We use a simple CNN and tune a few hyperparameters (network architecture, learning rate, batch size, optimizer)\n",
    "\n",
    "__Contents__\n",
    "\n",
    "1. Preliminaries\n",
    "    - Data loading with boto3 (AWS)\n",
    "    - Dataset class, dataloader, transforms\n",
    "    - Image visualisation\n",
    "    \n",
    "    \n",
    "2. Training and evaluation\n",
    "    - model architecture v1\n",
    "    - first shot training \n",
    "    - experiment : optimizer ? N_epochs ?\n",
    "    - evaluation : metrics table\n",
    "    - ROC curves\n",
    "   \n",
    "    \n",
    "3. Hyperparameter tuning\n",
    "    - code wrapping for ray.tune \n",
    "    - hp tuning for CNN architecture LR and batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminaries\n",
    "\n",
    "Contents :\n",
    "- data loading and AWS specific details\n",
    "- data split : train, val and test sets\n",
    "- custom ArthropodsDataset class \n",
    "- image visualization\n",
    "- transforms\n",
    "- network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__AWS specific__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3c = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'eva-arthropod'\n",
    "\n",
    "#ARN is arn:aws:s3:::eva-arthropod\n",
    "source_dirs = ['arthropod_highres_us_2/Araneae',\n",
    "               'arthropod_highres_us_2/Coleoptera',\n",
    "               'arthropod_highres_us_2/Diptera',\n",
    "               'arthropod_highres_us_2/Hemiptera',\n",
    "               'arthropod_highres_us_2/Hymenoptera',\n",
    "               'arthropod_highres_us_2/Lepidoptera', \n",
    "               'arthropod_highres_us_2/Odonata']  \n",
    "\n",
    "#test\n",
    "subfolder = 'arthropod_highres_us_2/Araneae/' \n",
    "contents = s3c.list_objects(Bucket=bucket, Prefix=subfolder)['Contents']\n",
    "for f in contents:\n",
    "    print(f['Key'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regular imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use GPU if available, otherwise CPU\n",
    "c = torch.cuda.device_count()\n",
    "print(\"Number of GPUs : \", c)\n",
    "if c > 0 :\n",
    "    print(torch.cuda.get_device_name(device=None))\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reproductibility__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproductibility in all places\n",
    "def seed_all(seed):\n",
    "    print(\">>> Using Seed : \", seed, \" <<<\")\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return None\n",
    "\n",
    "seed_all(2905)\n",
    "    \n",
    "# check pytorch version : 1.7.1\n",
    "print(\"Using PyTorch version \", torch.__version__)\n",
    "\n",
    "# for classification saving results in  a dataframe \n",
    "saving = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train/Val/Test split__\n",
    "\n",
    "90% train+val, 10% test. Val = 20% of train+val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [folder_name.split('/')[-1] for folder_name in source_dirs] \n",
    "class_names.sort() \n",
    "print(class_names)\n",
    "label_dic = {class_names[val]:val for val in range(len(class_names))}\n",
    "print(label_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = s3c.get_paginator('list_objects_v2') # iterator over result pages when querying s3\n",
    "\n",
    "N_images = []\n",
    "\n",
    "file_dic = {}\n",
    "\n",
    "for folder in source_dirs :\n",
    "    # class name\n",
    "    class_name = folder.split('/')[-1]\n",
    "    print('\\n', class_name)\n",
    "    # iterator over pages\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=folder)\n",
    "    # count images\n",
    "    files = []\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            if obj['Key'].endswith('.jpg'):\n",
    "                files.append(obj['Key'])\n",
    "    print(len(files))\n",
    "    N_images.append(len(files))\n",
    "    file_dic[class_name]=files\n",
    "\n",
    "N_min = min(N_images)\n",
    "print(\"\\nN_min total : \", N_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of images for each set from train, val and test percentages\n",
    "\n",
    "p1 = 0.9 # train_val percentage from initial dataset\n",
    "p2 = 0.2 # val_percentage from train_val\n",
    "\n",
    "N_test = ceil(N_min*(1-p1))\n",
    "print(\"N_test per class : \", N_test)\n",
    "\n",
    "N_val = ceil(N_min*p1*p2)\n",
    "print(\"N_val per class : \", N_val)\n",
    "\n",
    "for name in class_names:\n",
    "    print(\"N_train \"+name+' : ', len(file_dic[name])-N_test-N_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build file lists according to the split percentages and min number of samples per class\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for name in class_names : \n",
    "    files = file_dic[name]\n",
    "    test_files+=files[:N_test]\n",
    "    val_files+=files[N_test:N_test+N_val]\n",
    "    train_files+=files[N_test+N_val:]\n",
    "\n",
    "print(\"Train set: %s, \\nVal set :   %s, \\nTest set :  %s.\" %(len(train_files), len(val_files), len(test_files)))\n",
    "#print(train_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle lists : seed has been set above\n",
    "print(train_files[:5])\n",
    "random.shuffle(train_files)\n",
    "print(train_files[:5])\n",
    "random.shuffle(val_files)\n",
    "random.shuffle(test_files)\n",
    "\n",
    "\"\"\" To verify reproductibility OK\n",
    "['arthropod_highres_us_2/Araneae/3c628b041db2.jpg', 'arthropod_highres_us_2/Araneae/3c6491416c3f.jpg', 'arthropod_highres_us_2/Araneae/3c9737b52807.jpg', 'arthropod_highres_us_2/Araneae/3cacd14fe17d.jpg', 'arthropod_highres_us_2/Araneae/3cda1ee5743d.jpg']\n",
    "['arthropod_highres_us_2/Hymenoptera/df4734164730.jpg', 'arthropod_highres_us_2/Araneae/e65766cc8702.jpg', 'arthropod_highres_us_2/Lepidoptera/6396f66b8ed9.jpg', 'arthropod_highres_us_2/Hemiptera/c2ea24c86c40.jpg', 'arthropod_highres_us_2/Hymenoptera/6b5413623f03.jpg']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data augmentation\n",
    "\n",
    "# get file list from /augmented_images\n",
    "\n",
    "paginator = s3c.get_paginator('list_objects_v2')\n",
    "\n",
    "N_img_aug = []\n",
    "aug_files = []\n",
    "aug_file_dic = {}\n",
    "\n",
    "for folder in ['augmented_images'] :\n",
    "    # iterator over pages\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=folder)\n",
    "    # count images\n",
    "    files = []\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            if obj['Key'].endswith('.jpg'):\n",
    "                files.append(obj['Key'])\n",
    "    print(len(files))\n",
    "    print(files[:2])\n",
    "    N_img_aug.append(len(files))\n",
    "    aug_files+=files\n",
    "\n",
    "for c in class_names:\n",
    "    aug_file_dic[c]=[f for f in aug_files if c in f]\n",
    "    \n",
    "for name in class_names:\n",
    "    print(\"N_aug \"+name+' : ', len(aug_file_dic[name]))\n",
    "    \n",
    "\n",
    "N_min_aug = min([len(aug_file_dic[name]) for name in class_names])\n",
    "print(\"Min number of images available per class : \", N_min_aug)\n",
    "\n",
    "N_target = N_min_aug+N_min\n",
    "print(N_target)\n",
    "\n",
    "for name in class_names : \n",
    "    N_to_add = N_target - len([f for f in train_files if name in f]) - len([f for f in val_files if name in f]) - N_test #+N_min # total number of examples to add\n",
    "    #print(\"Total number of augmented images to add for class %s : %s\" %(name, N_to_add))\n",
    "    train_files = train_files + aug_file_dic[name][:ceil(N_to_add*0.8)]\n",
    "    val_files = val_files + aug_file_dic[name][ceil(N_to_add*0.8):N_to_add]\n",
    "    #print(len([f for f in train_files_aug if name in f]))\n",
    "    #print(len([f for f in val_files_aug if name in f]))\n",
    "    \n",
    "    \n",
    "print(\"Total number of training examples : \", len(train_files))\n",
    "print(\"Total number of validation examples : \", len(val_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data loading and preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a custom dataset for the arthropod images ###\n",
    "\n",
    "# file_list = dataset argument : train, val or test, list of paths as strings\n",
    "\n",
    "\n",
    "class ArthropodDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, file_list, bucket_name = 'eva-arthropod', transform=None): \n",
    "        self.bucket_name = bucket_name\n",
    "        self.files = file_list\n",
    "        self.s3_resource = boto3.resource('s3')\n",
    "        self.transform = transform\n",
    "        if transform is None:\n",
    "            self.transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(size=(224, 224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        # label is infered from the filename\n",
    "        if \"imaug\" in img_name:\n",
    "            label_str = img_name[17:].split('_')[0]\n",
    "        else:\n",
    "            label_str = img_name.split('/')[1] # ex : arthropod_highres/Araneae/69e98607339f.jpg --> Araneae\n",
    "        label = int(label_dic[label_str]) # label as integer\n",
    "\n",
    "        # we need to download the file from S3 to a temporary file locally\n",
    "        # we need to create the local file name\n",
    "        obj = self.s3_resource.Object(self.bucket_name, img_name)\n",
    "        tmp_name = '/tmp/'+img_name.split('/')[-1]\n",
    "        if '._' in tmp_name:\n",
    "            print(\"Warning\", label)\n",
    "            \"\"\"\n",
    "            tmp_name_split = tmp_name.split('._')\n",
    "            print(tmp_name, img_name, tmp_name_split)\n",
    "            tmp_name = ''.join(tmp_name_split)\n",
    "            \"\"\"\n",
    "        #print(img_name, tmp_name)\n",
    "        # now we can actually download from S3 to a local place\n",
    "        with open(tmp_name, 'wb') as f:\n",
    "            obj.download_fileobj(f)\n",
    "            f.flush()\n",
    "            f.close()\n",
    "            image = Image.open(tmp_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transforms  ###\n",
    "\n",
    "# train set : 224*224 images as input because min input size of mobilenet, resnet18 etc architectures \n",
    "# mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] because they are the values of the ImageNet data     \n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(224, 224)),\n",
    "    #torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# test set : same steps except the data augmentation step     \n",
    "# idem for the mean and std dev values    \n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: visualisation\n",
    "\n",
    "bucket_name = 'eva-arthropod'\n",
    "img_name = 'arthropod_highres/Araneae/1c395363bae7.jpg'\n",
    "obj = boto3.resource('s3').Object(bucket_name, img_name)\n",
    "tmp_name = '/tmp/'+img_name.split('/')[-1]\n",
    "print(tmp_name)\n",
    "# now we can actually download from S3 to a local place\n",
    "with open(tmp_name, 'wb') as f:\n",
    "    obj.download_fileobj(f)\n",
    "    f.flush()\n",
    "    f.close()\n",
    "    image = Image.open(tmp_name)\n",
    " \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data loaders ###\n",
    "\n",
    "train_dataset = ArthropodDataset( train_files, transform = train_transform)\n",
    "val_dataset = ArthropodDataset(val_files, transform = train_transform)\n",
    "test_dataset=ArthropodDataset(test_files, transform = test_transform)\n",
    "\n",
    "# dataloaders objects corresponding to the train and test sets\n",
    "\n",
    "B=16 # batch size for the data loaders\n",
    "print(\"Batch size : \", B)\n",
    "\n",
    "NUM_WORKERS = 15\n",
    "\n",
    "dl_train=torch.utils.data.DataLoader(train_dataset, batch_size=B, shuffle=True, num_workers=NUM_WORKERS) \n",
    "dl_val=torch.utils.data.DataLoader(val_dataset, batch_size=B, shuffle=True, num_workers=NUM_WORKERS)  \n",
    "dl_test=torch.utils.data.DataLoader(test_dataset, batch_size=B, shuffle=False, num_workers=NUM_WORKERS)\n",
    "print(\"Number of training batches: \",  len(dl_train))\n",
    "print(\"Number of val batches: \",  len(dl_val))\n",
    "print(\"Number of test batches: \",  len(dl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data visualization ###\n",
    "# B : batchsize = 16\n",
    "def show_images(images, labels, preds):\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = image * std + mean\n",
    "        image = np.clip(image, 0., 1.)\n",
    "        plt.imshow(image)\n",
    "        col = 'green'\n",
    "        if preds[i] != labels[i]:\n",
    "            col = 'red'            \n",
    "        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n",
    "        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "images, labels = next(iter(dl_train))\n",
    "show_images(images, labels, labels)\n",
    "\n",
    "images, labels = next(iter(dl_test))\n",
    "show_images(images, labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define the network  architecture__\n",
    "\n",
    "Custom network with 3 convolutional layers and 2 fully connected layers.\n",
    "\n",
    "Tests\n",
    "\n",
    " - dropout is not great here (1D dropout : During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution. Each channel will be zeroed out independently on every forward call. Furthermore, the outputs are scaled by a factor of 1/(1-p) during training. This means that during evaluation the module simply computes an identity function. Choice : p = 0.2, dropout layer between the first and the second fully connected layers. Dropout not kept for this CNN, either too small or not trained on a high enough number of epochs to have a return on investment with dropout.\n",
    " \n",
    "- optimizer : Adam, RMSprop and SGD tested. SGD performs better here. \n",
    "\n",
    "NB : CrossEntropyLoss =  F.nll_loss(output, target) as loss function + F.log_softmax(x, dim=1) as final layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(class_names)\n",
    "NUM_CONV_1=16 # also tried : 32, and stride = 1\n",
    "NUM_CONV_2=32 # also tried : 64\n",
    "NUM_CONV_3=32 # also tried : 32\n",
    "NUM_FC=512 # also tried : 1024\n",
    "p=0.2 # dropout probability\n",
    "\n",
    "class myCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myCNN,self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(3,NUM_CONV_1,5,2) # kernel_size = 5, stride = 2, no padding \n",
    "        self.conv_2 = nn.Conv2d(NUM_CONV_1,NUM_CONV_2,5,1) # kernel_size = 5, stride = 1, no padding \n",
    "        self.conv_3 = nn.Conv2d(NUM_CONV_2,NUM_CONV_3,5,1) # kernel_size = 5, , stride = 1, no padding \n",
    "        #self.drop = nn.Dropout(p=0.2)        \n",
    "        self.fc_1 = nn.Linear(10*10*NUM_CONV_3, NUM_FC)\n",
    "        self.fc_2 = nn.Linear(NUM_FC,NUM_CLASSES)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(self.drop(self.fc_1(x)))\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        return x\n",
    "\n",
    "# define model \n",
    "model = myCNN()\n",
    "\n",
    "model.to(device) # puts model on GPU / CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trainable parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Number of trainable parameters : \", params) # 1.682.183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and evaluation \n",
    "\n",
    "Contents : \n",
    "* Training without hp tuning. \n",
    "* Metrics and visualizations to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization hyperparameters\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01) \n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr = 0.02)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training v1 ##\n",
    "\n",
    "def train(model, N_epochs, train_loader, test_loader):\n",
    "    \"\"\"\n",
    "    model : neural network like myCNN()\n",
    "    N_epochs : int\n",
    "    train_loader : dataloader instance to iterate over training batches\n",
    "    test_loader : idem, for val or test set\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print('Starting training..')\n",
    "    for epoch in range(N_epochs):\n",
    "        print('\\n'+'='*20+'\\nStarting epoch '+str(epoch+1) + '/'+str(N_epochs)+'\\n'+'='*20)\n",
    "        # training\n",
    "        model.train() # mode \"train\" agit sur \"dropout\" ou \"batchnorm\"\n",
    "        for batch_idx, (x, target) in enumerate(train_loader):\n",
    "            #print(len(x))\n",
    "            #print(x.shape)\n",
    "            optimizer.zero_grad()\n",
    "            x, target = Variable(x).to(device), Variable(target).to(device)\n",
    "            #print(len(x))\n",
    "            out = model(x)\n",
    "            #print(len(out), len(target))\n",
    "            loss = loss_fn(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx %100 ==0:\n",
    "                print('epoch {} - batch {} [{}/{}] - training loss: {}'.format(epoch+1,batch_idx,batch_idx*len(x),\n",
    "                        len(train_loader.dataset),loss.item()))\n",
    "        # testing -- val set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x, target) in enumerate(test_loader):\n",
    "                x, target = x.to(device), target.to(device)\n",
    "                out = model(x)\n",
    "                loss = loss_fn(out, target)\n",
    "                # _, prediction = torch.max(out.data, 1)\n",
    "                prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
    "                correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        taux_classif = 100. * correct / len(test_loader.dataset)\n",
    "        print('Val Accuracy: {}/{} (i.e. {:.2f}%, error: {:.2f}%)\\n'.format(correct,\n",
    "         len(test_loader.dataset), taux_classif, 100.-taux_classif))\n",
    "    print(\"Elapsed : %s min\" %ceil((time.time()-start)/60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Experiment : at which point does the model begin to overfit ?__\n",
    "\n",
    "After 16 epochs it was still not clearly overfitting. But we cannot afford to train our models for such a long time. Bigger models are longer to train and since an AWS session times out after 12 hours of activity, we would systematically be running out of time. Of course we have thought of checkpointing and we have implemented it too. But return on invested training time stays low. So we arbitrarily train our models for around 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training v2 ##\n",
    "\n",
    "N_epochs = 14 \n",
    "\n",
    "def train_with_history(model, N_epochs, train_loader, test_loader, checkpoint_dir = None):\n",
    "    \"\"\"\n",
    "    model : neural network like myCNN()\n",
    "    N_epochs : int\n",
    "    train_loader : dataloader instance to iterate over training batches\n",
    "    test_loader : idem, for val or test set\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print('Starting training..')\n",
    "    \n",
    "    ### added \n",
    "    \"\"\"\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    \"\"\"\n",
    "    ### end added\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    batch_idx_list = []\n",
    "    epoch_list = [n for n in range(N_epochs)]\n",
    "    \n",
    "    for epoch in range(N_epochs):\n",
    "        print('\\n'+'='*20+'\\nStarting epoch '+str(epoch+1) + '/'+str(N_epochs)+'\\n'+'='*20)\n",
    "        # training\n",
    "        model.train() # mode \"train\" agit sur \"dropout\" ou \"batchnorm\"\n",
    "        for batch_idx, (x, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x, target = Variable(x).to(device), Variable(target).to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx %100 ==0:\n",
    "                print('epoch {} - batch {} [{}/{}] - training loss: {}'.format(epoch+1,batch_idx,batch_idx*len(x),\n",
    "                        len(train_loader.dataset),loss.item()))\n",
    "                train_loss_history.append(loss.item())\n",
    "                batch_idx_list.append(batch_idx+epoch*ceil(len(train_loader.dataset)/len(x))) # number of batches already processed\n",
    "        \n",
    "        ### added\n",
    "        #path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        #torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "        ### end added\n",
    "        \n",
    "        # testing -- val set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x, target) in enumerate(test_loader):\n",
    "                x, target = x.to(device), target.to(device)\n",
    "                out = model(x)\n",
    "                loss = loss_fn(out, target)\n",
    "                # _, prediction = torch.max(out.data, 1)\n",
    "                prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
    "                correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        taux_classif = 100. * correct / len(test_loader.dataset)\n",
    "        print('Val Accuracy: {}/{} (i.e. {:.2f}%, error: {:.2f}%)\\n'.format(correct,\n",
    "         len(test_loader.dataset), taux_classif, 100.-taux_classif))\n",
    "        val_loss_history.append(loss.item())\n",
    "        val_acc_history.append(taux_classif)\n",
    "    \n",
    "    print(\"Elapsed : %s min\" %ceil((time.time()-start)/60))\n",
    "    hist_dic= {'train_loss': train_loss_history, 'epochs' : epoch_list,\n",
    "             'val_loss': val_loss_history, 'val_acc': val_acc_history, 'batches' : batch_idx_list}\n",
    "    return model, hist_dic\n",
    "\n",
    "\n",
    "    \n",
    "#trained_model, hist_dic = train_with_history(model, N_epochs, dl_train, dl_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointing utils\n",
    "\n",
    "def load_checkpoint(filename='cp_CNN', checkpoint_dir='models', bucket=bucket):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    ------\n",
    "    filename : str, choose something like cp_modelType_version_epoch\n",
    "    checkpoint_dir : str, \"/models\"\n",
    "    bucket : str, \"eva_arthropod\"\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    model_state : model state dict\n",
    "    optimizer_state : optimizer state dict\n",
    "    \"\"\"\n",
    "    boto3.resource('s3').meta.client.download_file(bucket, \n",
    "                                                   os.path.join(checkpoint_dir, filename), \n",
    "                                                   '/tmp/loaded_checkpoint')\n",
    "    model_state, optimizer_state = torch.load('/tmp/loaded_checkpoint')\n",
    "    print(\"Successfully downloaded checkpoint from s3 bucket : \" ,filename)\n",
    "    return model_state, optimizer_state \n",
    "\n",
    "def save_checkpoint(net, optimizer, filename='cp_CNN', checkpoint_dir='models', bucket=bucket):\n",
    "    torch.save((net.state_dict(), optimizer.state_dict()), '/tmp/saved_checkpoint')\n",
    "    s3_path = os.path.join(checkpoint_dir, filename)\n",
    "    print(s3_path)\n",
    "    boto3.resource('s3').meta.client.upload_file(Filename = '/tmp/saved_checkpoint', \n",
    "                                                 Bucket = bucket, \n",
    "                                                 Key = s3_path)\n",
    "    print(\"Successfully uploaded checkpoint %s to s3 bucket under name %s.\" %(filename, s3_path))\n",
    "\n",
    "# test\n",
    "# save_checkpoint(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training with checkpoints ##\n",
    "\n",
    "\n",
    "def train_with_history(model, N_epochs, train_loader, test_loader, make_checkpoints = True, warm_start = False, warm_filename=None):\n",
    "    \"\"\"\n",
    "    model : neural network like myCNN()\n",
    "    N_epochs : int\n",
    "    train_loader : dataloader instance to iterate over training batches\n",
    "    test_loader : idem, for val or test set\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print('Starting training..')\n",
    "    \n",
    "    if warm_start :\n",
    "        model_state, optimizer_state  = load_checkpoint(filename = warm_filename)\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "            \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    batch_idx_list = []\n",
    "    epoch_list = [n for n in range(N_epochs)]\n",
    "    \n",
    "    for epoch in range(N_epochs):\n",
    "        print('\\n'+'='*20+'\\nStarting epoch '+str(epoch+1) + '/'+str(N_epochs)+'\\n'+'='*20)\n",
    "        # training\n",
    "        model.train() # mode \"train\" agit sur \"dropout\" ou \"batchnorm\"\n",
    "        for batch_idx, (x, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x, target = Variable(x).to(device), Variable(target).to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx %100 ==0:\n",
    "                print('epoch {} - batch {} [{}/{}] - training loss: {}'.format(epoch+1,batch_idx,batch_idx*len(x),\n",
    "                        len(train_loader.dataset),loss.item()))\n",
    "                train_loss_history.append(loss.item())\n",
    "                batch_idx_list.append(batch_idx+epoch*ceil(len(train_loader.dataset)/len(x))) # number of batches already processed\n",
    "        \n",
    "        if make_checkpoints :\n",
    "            if epoch == 0 :\n",
    "                save_checkpoint(model, optimizer, filename)                \n",
    "            elif val_acc_history[-1]>val_acc_history[-2]:\n",
    "                print(\"Improvement in validation accuracy by %s percents\" %(val_acc_history[-1]-val_acc_history[-2]))\n",
    "                save_checkpoint(model, optimizer, filename)\n",
    "            else : \n",
    "                pass\n",
    "        \n",
    "        # testing -- val set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x, target) in enumerate(test_loader):\n",
    "                x, target = x.to(device), target.to(device)\n",
    "                out = model(x)\n",
    "                loss = loss_fn(out, target)\n",
    "                # _, prediction = torch.max(out.data, 1)\n",
    "                prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
    "                correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        taux_classif = 100. * correct / len(test_loader.dataset)\n",
    "        print('Val Accuracy: {}/{} (i.e. {:.2f}%, error: {:.2f}%)\\n'.format(correct,\n",
    "         len(test_loader.dataset), taux_classif, 100.-taux_classif))\n",
    "        val_loss_history.append(loss.item())\n",
    "        val_acc_history.append(taux_classif)\n",
    "    \n",
    "    print(\"Elapsed : %s min\" %ceil((time.time()-start)/60))\n",
    "    hist_dic= {'train_loss': train_loss_history, 'epochs' : epoch_list,\n",
    "             'val_loss': val_loss_history, 'val_acc': val_acc_history, 'batches' : batch_idx_list}\n",
    "    return model, hist_dic\n",
    "\n",
    "\n",
    "# model, N_epochs, train_loader, test_loader, make_checkpoints = True, warm_start = False    \n",
    "trained_model, hist_dic = train_with_history(model, N_epochs, \n",
    "                                             dl_train, dl_val, \n",
    "                                             warm_start=True, \n",
    "                                             warm_filename = 'cp_CNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saving\n",
    "\n",
    "filename = 'model_cnn_1_aug.pth'\n",
    "torch.save(trained_model.state_dict(), filename)\n",
    "print(\"saved model locally to {}\".format(filename))\n",
    "\n",
    "boto3.resource('s3').meta.client.upload_file(filename, bucket, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test : how to reopen model - OK\n",
    "boto3.resource('s3').meta.client.download_file(bucket, filename, os.path.join('/tmp', filename))\n",
    "state_dic = torch.load(os.path.join('/tmp', filename))\n",
    "new_model = myCNN()\n",
    "new_model.load_state_dict(state_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Note : test with 3 classe without training : Average loss: 0.0695, Accuracy: 379/1140 (33.246%)\n",
    " consistent with a 1/3 guessing principle. \n",
    " \n",
    "Test with 7 classes without training : Average loss: 0.1223, Accuracy: 396/2562 (15.457%) slightly better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple accuracy computation ###\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            #print(data.shape)\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "        \n",
    "            outputs = model(data)            \n",
    "            loss += loss_fn(outputs, target).item() #data[0]            \n",
    "            pred = outputs.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "                \n",
    "    loss /= len(data_loader.dataset)        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    \n",
    "    return None\n",
    "\n",
    "#evaluate(model, dl_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Macro and micro metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get full performance metrics ###\n",
    "## Version 2 -- Probabilities to feed ROC curves ##\n",
    "\n",
    "def get_pred(model, data_loader):\n",
    "    model.eval()\n",
    "    pred = torch.LongTensor()\n",
    "    target= torch.LongTensor()\n",
    "    proba = torch.LongTensor()\n",
    "    s = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data_i, target_i in data_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data_i = data_i.cuda()\n",
    "                \n",
    "            outputs = model(data_i)\n",
    "            pred_i = np.argmax(outputs,axis=1)\n",
    "            pred = torch.cat((pred, pred_i), dim=0)\n",
    "            target = torch.cat((target, target_i), dim=0)\n",
    "            proba = torch.cat((proba, s(outputs)), dim=0)\n",
    "        \n",
    "    return pred, target, proba\n",
    "\n",
    "\n",
    "train_pred, train_target, train_proba = get_pred(trained_model, dl_train) # trained_model\n",
    "val_pred, val_target, val_proba = get_pred(trained_model, dl_val) # trained_model\n",
    "\n",
    "print(\"\\nPerformance on training set\")\n",
    "print(classification_report(train_target, train_pred, target_names=class_names))\n",
    "print(\"\\nPerformance on val set\")\n",
    "print(classification_report(val_target, val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we clearly have brought our model to overfitting by making it learn during 20 epochs in total (6 -> checkpoint + 14 above). Test accuracy is accordingly poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set \n",
    "test_pred, test_target, test_proba = get_pred(trained_model, dl_test) # trained_model\n",
    "\n",
    "print(\"\\nPerformance on training set\")\n",
    "print(classification_report(test_target, test_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best validation checkpoint\n",
    "\n",
    "model_state, optimizer_state  = load_checkpoint()\n",
    "new_model.load_state_dict(model_state)\n",
    "\n",
    "# test set \n",
    "test_pred, test_target, test_proba = get_pred(new_model, dl_test) # trained_model\n",
    "\n",
    "print(\"\\nPerformance on training set\")\n",
    "print(classification_report(test_target, test_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Focus : ROC curves and area under ROC for a multiclass problem__\n",
    " \n",
    "NB : See 3.3.2.15.2. Multi-class case [here](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics).\n",
    "\n",
    "ROC curves are typically used in binary classification to study the output of a classifier. In order to extend ROC curve and ROC area to multi-label classification, it is necessary to binarize the output. One ROC curve can be drawn per label, but one can also draw a ROC curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).\n",
    "\n",
    "Another evaluation measure for multi-label classification is macro-averaging, which gives equal weight to the classification of each label.\n",
    "Here in order to plot the ROC curves for the multilabel problem, we compute the macro-average ROC curve and the corresponding ROC areas.   \n",
    "\n",
    "Note : The `sklearn.metrics.roc_auc_score` function can be used for multi-class classification with two schemes. The One-vs-One scheme compares every unique pairwise combination of classes. The One-vs-Rest schema compares every class against the rest of the others. Here we calculate the AUC using the OvO scheme. We report a macro average, and a prevalence-weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from scipy import interp\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From torch.tensors to numpy.arrays\n",
    "\n",
    "print(test_target.size())\n",
    "test_target_array = test_target.detach().cpu().numpy()\n",
    "\n",
    "# one-hot encoding needed for multiclass ROC\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])\n",
    "\n",
    "test_target_array = get_one_hot(test_target_array, NUM_CLASSES)\n",
    "print(test_target_array.shape)\n",
    "\n",
    "\n",
    "test_proba_array = test_proba.detach().cpu().numpy()\n",
    "print(test_proba_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ## \n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_target_array[:, i], test_proba_array[:, i])  # y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_target_array.ravel(), test_proba_array.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(NUM_CLASSES)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(NUM_CLASSES):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= NUM_CLASSES\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate - Test set')\n",
    "plt.ylabel('True Positive Rate - Test set')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Area under ROC for a multiclass problem - One-vs-One ##\n",
    "\n",
    "macro_roc_auc_ovo = roc_auc_score(val_target, val_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "\n",
    "weighted_roc_auc_ovo = roc_auc_score(val_target, val_proba, multi_class=\"ovo\", average=\"weighted\")\n",
    " \n",
    "\n",
    "print(\"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Learning curves__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(hist_dic):\n",
    "    train_loss_history, epoch_list = hist_dic['train_loss'], hist_dic['epochs']\n",
    "    val_loss_history, val_acc_history, batch_idx_list = hist_dic['val_loss'], hist_dic['val_acc'], hist_dic['batches']  \n",
    "    # plot learning curves - training set\n",
    "    plt.plot(batch_idx_list, train_loss_history,  \n",
    "             color='blue', linestyle='dashed', \n",
    "             marker = '*', markerfacecolor='black')\n",
    "    plt.xlabel(\"Number of processed training batches\")\n",
    "    plt.ylabel(\"Training loss\")\n",
    "    plt.title('Training loss across training')\n",
    "    plt.show()\n",
    "    # plot learning curves - val set\n",
    "    plt.plot(epoch_list, val_loss_history, \n",
    "             color = 'red', linestyle = 'dashed', \n",
    "             marker = '*', markerfacecolor = 'black')\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Val loss\")\n",
    "    plt.title('Val loss across training')\n",
    "    plt.show()\n",
    "    plt.plot(epoch_list, val_acc_history,  \n",
    "             color = 'green', linestyle = 'dashed', \n",
    "             marker = '*', markerfacecolor = 'black')\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Val accuracy\")\n",
    "    plt.title('Val accuracy across training')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(hist_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting after 4+6 epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optional : save predictions as CSVs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving results ###\n",
    "\n",
    "saving = False\n",
    "\n",
    "if saving:\n",
    "    print(\"Saving results\")\n",
    "    train_df = pd.DataFrame({\"pred\":train_pred, \"target\": train_target})\n",
    "    val_df = pd.DataFrame({\"pred\":val_pred, \"target\": val_target})\n",
    "    train_df.to_csv(\"train_results_CNN.csv\")\n",
    "    val_df.to_csv(\"val_results_CNN.csv\")\n",
    "    \n",
    "# Print model's state_dict\n",
    "def print_model_info(model):\n",
    "    print(\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "    # Print optimizer's state_dict\n",
    "    print(\"Optimizer's state_dict:\")\n",
    "    for var_name in optimizer.state_dict():\n",
    "        print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    return None\n",
    "\n",
    "#print_model_info(resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter tuning\n",
    "\n",
    "We perform a (grid) search to select the best combination of batch size, learning rate and optimizer. We will keep the best model as reference. \n",
    "\n",
    "We use the framework of ray.tune to benefit from its reporting functionalities during hyperparameter tuning. Therefore we need to repackage the code a bit. We followed this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html). \n",
    "\n",
    "Alternative : https://discuss.pytorch.org/t/what-is-the-best-way-to-perform-hyper-parameter-search-in-pytorch/19943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data loaders ###\n",
    "\n",
    "def load_data(train_files, val_files, test_files):\n",
    "\n",
    "    # train set : 224*224 images as input because min input size of mobilenet, resnet18 etc architectures \n",
    "    # mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] because they are the values of the ImageNet data     \n",
    "    train_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size=(224, 224)),\n",
    "        #torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # test set : same steps except the data augmentation step     \n",
    "    # idem for the mean and std dev values    \n",
    "    test_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size=(224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = ArthropodDataset(train_files, transform = train_transform)\n",
    "    val_dataset = ArthropodDataset(val_files, transform = train_transform)\n",
    "    test_dataset=ArthropodDataset(test_files, transform = test_transform)\n",
    "\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# test OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter choice : \n",
    "* network will not be configurable id est the number of layers or their caracteristics will not be tuned here;\n",
    "* the optimizer : SGD, RMSProp or Adam. RMSProp was used to train the original MobileNet model we use for transfer learning. We also test an alternative optimizer. We need to run the hp tuning process several times.\n",
    "* learning rate : the learning rate value is to be tuned, it is one of the most impactful hyperparameters in deep learning;\n",
    "* batch size\n",
    "\n",
    "Note : \n",
    "\n",
    "    CLASS torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "    \n",
    "    CLASS torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hp tuning v2 : tune the architecture too__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search space ###\n",
    "\n",
    "N_epochs = 8\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "config = {            \n",
    "            \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "            \"batch_size\": tune.choice([4, 8, 16]),\n",
    "            \"NUM_CONV_1\": tune.choice([16, 32]),\n",
    "            \"NUM_FC\": tune.choice([512, 1024])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(class_names)\n",
    "#NUM_CONV_1=16 # try 32\n",
    "NUM_CONV_2=32 # try 64\n",
    "NUM_CONV_3=32 # try 64\n",
    "#NUM_FC=512 # (try 1024)\n",
    "\n",
    "class myCNN(nn.Module):\n",
    "    def __init__(self, NUM_CONV_1, NUM_FC):\n",
    "        super(myCNN,self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(3,NUM_CONV_1,5,2) # kernel_size = 5, stride = 2, no padding \n",
    "        self.conv_2 = nn.Conv2d(NUM_CONV_1,NUM_CONV_2,5,1) # kernel_size = 5, stride = 1, no padding \n",
    "        self.conv_3 = nn.Conv2d(NUM_CONV_2,NUM_CONV_3,5,1) # kernel_size = 5, , stride = 1, no padding \n",
    "        #self.drop = nn.Dropout(p=0.2)        \n",
    "        self.fc_1 = nn.Linear(10*10*NUM_CONV_3, NUM_FC)\n",
    "        self.fc_2 = nn.Linear(NUM_FC,NUM_CLASSES)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(self.drop(self.fc_1(x)))\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        return x\n",
    "\n",
    "# test \n",
    "myCNN(16, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training ###\n",
    "\n",
    "# with multiplicative learning rate decay  \n",
    "\n",
    "\n",
    "def train_n_tune(config, checkpoint_dir=None): # config, N_epochs, train_files, val_files, test_files, \n",
    "    \n",
    "    net = myCNN(config[\"NUM_CONV_1\"], config[\"NUM_FC\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer =  torch.optim.SGD(net.parameters(), lr=config[\"lr\"]) ## To adapt ##\n",
    "    lr_lambda = lambda x : 0.9999 \n",
    "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    train_subset, val_subset, testset = load_data(train_files, val_files, test_files)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=1)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=1)\n",
    "\n",
    "    def test_accuracy(net, device=\"cpu\"): # train_files, val_files, test_files are global \n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return correct / total\n",
    "    \n",
    "    for epoch in range(N_epochs):  # loop over the dataset multiple times\n",
    "        print(\"--- Epoch %s ---\" %(epoch+1))\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            try :\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                epoch_steps += 1\n",
    "                if i % 200 == 199:  # print every 200 mini-batches\n",
    "                    print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                    running_loss / epoch_steps))\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            except : \n",
    "                print(\"Batch number %s left out / Training (OSError : missing bytes)\" %i)\n",
    "                # OSError: image file is truncated (X bytes not processed)\n",
    "        print(\"Average loss for epoch %s : %s\" %(epoch+1, running_loss/epoch_steps))\n",
    "        \n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            try :\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = net(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.cpu().numpy()\n",
    "                    val_steps += 1\n",
    "            except :\n",
    "                print(\"Batch number %s left out / Validation (OSError : missing bytes)\" %i)\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    test_acc = test_accuracy(net, device)\n",
    "    print(\"Current test set accuracy: {}\".format(test_acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main : perform hp tuning ###\n",
    "\n",
    "# train_files, val_files, test_files,  already defined above \n",
    "\n",
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = load_data(train_files, val_files, test_files)\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    \n",
    "    result = tune.run(\n",
    "        partial(train_n_tune), # config=config, N_epochs=max_num_epochs, train_files, val_files, test_files\n",
    "        resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model =  myCNN(best_trial.config[\"NUM_CONV_1\"], best_trial.config[\"NUM_FC\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "    \n",
    "    def test_accuracy(net, device=\"cpu\"): # train_files, val_files, test_files are global \n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return correct / total\n",
    "    \n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=6, max_num_epochs=10, gpus_per_trial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
