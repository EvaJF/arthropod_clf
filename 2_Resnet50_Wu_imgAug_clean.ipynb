{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arthropod Classification with a pretrained network : Resnet50 by Wu et al.\n",
    "\n",
    "See article __IP102: A Large-Scale Benchmark Dataset for Insect Pest Recognition__\n",
    "by Xiaoping Wu, Chi Zhan, Yu-Kun Lai, Ming-Ming Cheng, Jufeng Yang from College of Computer Science, Nankai University, Tianjin, China and School of Computer Science and Informatics, Cardiff University, Cardiff, UK\n",
    "\n",
    "__Abstract of the article:__\n",
    "\n",
    "*Insect pests are one of the main factors affecting agri- cultural product yield. Accurate recognition of insect pests facilitates timely preventive measures to avoid economic losses. However, the existing datasets for the visual clas- sification task mainly focus on common objects, e.g., flow- ers and dogs. This limits the application of powerful deep learning technology on specific domains like the agricul- tural field. In this paper, we collect a large-scale dataset named IP102 for insect pest recognition. Specifically, it contains more than 75, 000 images belonging to 102 cat- egories, which exhibit a natural long-tailed distribution. In addition, we annotate about 19, 000 images with bounding boxes for object detection. The IP102 has a hierarchical taxonomy and the insect pests which mainly affect one spe- cific agricultural product are grouped into the same upper- level category. Furthermore, we perform several baseline experiments on the IP102 dataset, including handcrafted and deep feature based classification methods. Experimen- tal results show that this dataset has the challenges of inter- and intra- class variance and data imbalance. We believe our IP102 will facilitate future research on practical insect pest control, fine-grained visual classification, and imbal- anced learning fields. We make the dataset and pre-trained models publicly available at https://github.com/xpwu95/IP102.*\n",
    "\n",
    "__Contents__\n",
    "\n",
    "1. Preliminaries\n",
    "    - Data loading with boto3 (AWS)\n",
    "    - Dataset class, dataloader, transforms\n",
    "    - Image visualisation\n",
    "    \n",
    "    \n",
    "2. First runs \n",
    "\n",
    "    - A. Transfer learning \n",
    "        - utils : learning curves, checkpointing\n",
    "        - train v4 : history : checkpointing + warm start\n",
    "    - B. Fine-tuning\n",
    "    \n",
    "    \n",
    "3. Hyperparameter tuning\n",
    "    - code wrapping for ray.tune \n",
    "    - hp tuning for the last layer only (transfer learning)\n",
    "    - hp tuning for the whole network (fine-tuning)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__AWS specific__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3c = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'eva-arthropod'\n",
    "root_dir =  'arthropod_highres' \n",
    "\n",
    "#ARN is arn:aws:s3:::eva-arthropod\n",
    "source_dirs = ['arthropod_highres_us_2/Araneae',\n",
    "               'arthropod_highres_us_2/Coleoptera',\n",
    "               'arthropod_highres_us_2/Diptera',\n",
    "               'arthropod_highres_us_2/Hemiptera',\n",
    "               'arthropod_highres_us_2/Hymenoptera',\n",
    "               'arthropod_highres_us_2/Lepidoptera', \n",
    "               'arthropod_highres_us_2/Odonata']  \n",
    "\n",
    "subfolder = 'arthropod_highres/Araneae/' #test\n",
    "contents = s3c.list_objects(Bucket=bucket, Prefix=subfolder)['Contents']\n",
    "for f in contents:\n",
    "    print(f['Key'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regular imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from functools import partial\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use GPU if available, otherwise CPU\n",
    "c = torch.cuda.device_count()\n",
    "print(\"Number of GPUs : \", c)\n",
    "if c > 0 :\n",
    "    print(torch.cuda.get_device_name(device=None))\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reproductibility__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproductibility in all places\n",
    "def seed_all(seed):\n",
    "    print(\">>> Using Seed : \", seed, \" <<<\")\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return None\n",
    "\n",
    "seed_all(2905)\n",
    "    \n",
    "# check pytorch version : 1.7.1\n",
    "print(\"Using PyTorch version \", torch.__version__)\n",
    "\n",
    "# for classification saving results in  a dataframe \n",
    "saving = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train/Val/Test split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [folder_name.split('/')[-1] for folder_name in source_dirs] # to adapt\n",
    "class_names.sort() \n",
    "print(class_names)\n",
    "label_dic = {class_names[val]:val for val in range(len(class_names))}\n",
    "print(label_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = s3c.get_paginator('list_objects_v2')\n",
    "\n",
    "N_images = []\n",
    "\n",
    "file_dic = {}\n",
    "\n",
    "for folder in source_dirs :\n",
    "    # class name\n",
    "    class_name = folder.split('/')[-1]\n",
    "    print('\\n', class_name)\n",
    "    # iterator over pages\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=folder)\n",
    "    # count images\n",
    "    files = []\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            if obj['Key'].endswith('.jpg'):\n",
    "                files.append(obj['Key'])\n",
    "    print(len(files))\n",
    "    N_images.append(len(files))\n",
    "    file_dic[class_name]=files\n",
    "\n",
    "N_min = min(N_images)\n",
    "print(\"\\nN_min total : \", N_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, val and test percentages\n",
    "\n",
    "p1 = 0.9 # train_val percentage from initial dataset\n",
    "p2 = 0.2 # val_percentage from train_val\n",
    "\n",
    "N_test = ceil(N_min*(1-p1))\n",
    "print(\"N_test per class : \", N_test)\n",
    "\n",
    "N_val = ceil(N_min*p1*p2)\n",
    "print(\"N_val per class : \", N_val)\n",
    "\n",
    "for name in class_names:\n",
    "    print(\"N_train \"+name+' : ', len(file_dic[name])-N_test-N_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for name in class_names : \n",
    "    files = file_dic[name]\n",
    "    test_files+=files[:N_test]\n",
    "    val_files+=files[N_test:N_test+N_val]\n",
    "    train_files+=files[N_test+N_val:]\n",
    "\n",
    "print(len(train_files), len(val_files), len(test_files))\n",
    "print(train_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle lists : seed has been set above\n",
    "print(train_files[:5])\n",
    "random.shuffle(train_files)\n",
    "print(train_files[:5])\n",
    "random.shuffle(val_files)\n",
    "random.shuffle(test_files)\n",
    "\n",
    "\"\"\" To verify reproductibility OK\n",
    "['arthropod_highres_us_2/Araneae/3c628b041db2.jpg', 'arthropod_highres_us_2/Araneae/3c6491416c3f.jpg', 'arthropod_highres_us_2/Araneae/3c9737b52807.jpg', 'arthropod_highres_us_2/Araneae/3cacd14fe17d.jpg', 'arthropod_highres_us_2/Araneae/3cda1ee5743d.jpg']\n",
    "['arthropod_highres_us_2/Hymenoptera/df4734164730.jpg', 'arthropod_highres_us_2/Araneae/e65766cc8702.jpg', 'arthropod_highres_us_2/Lepidoptera/6396f66b8ed9.jpg', 'arthropod_highres_us_2/Hemiptera/c2ea24c86c40.jpg', 'arthropod_highres_us_2/Hymenoptera/6b5413623f03.jpg']\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data aug__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file list from /augmented_images\n",
    "\n",
    "paginator = s3c.get_paginator('list_objects_v2')\n",
    "\n",
    "N_img_aug = []\n",
    "aug_files = []\n",
    "aug_file_dic = {}\n",
    "\n",
    "for folder in ['augmented_images'] :\n",
    "    # iterator over pages\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=folder)\n",
    "    # count images\n",
    "    files = []\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            if obj['Key'].endswith('.jpg'):\n",
    "                files.append(obj['Key'])\n",
    "    print(len(files))\n",
    "    print(files[:2])\n",
    "    N_img_aug.append(len(files))\n",
    "    aug_files+=files\n",
    "\n",
    "for c in class_names:\n",
    "    aug_file_dic[c]=[f for f in aug_files if c in f]\n",
    "    \n",
    "for name in class_names:\n",
    "    print(\"N_aug \"+name+' : ', len(aug_file_dic[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target number of images for each class so that the dataset is balanced\n",
    "\n",
    "for name in class_names:\n",
    "    print(\"N_train \"+name+' : ', len(file_dic[name])-N_test-N_val)\n",
    "\n",
    "N_min_aug = min([len(aug_file_dic[name]) for name in class_names])\n",
    "print(\"Min number of images available per class : \", N_min_aug)\n",
    "\n",
    "N_target = N_min_aug+N_min\n",
    "print(N_target)\n",
    "\n",
    "for name in class_names : \n",
    "    N_to_add = N_target - len([f for f in train_files if name in f]) - len([f for f in val_files if name in f]) - N_test #+N_min # total number of examples to add\n",
    "    #print(\"Total number of augmented images to add for class %s : %s\" %(name, N_to_add))\n",
    "    train_files = train_files + aug_file_dic[name][:ceil(N_to_add*0.8)]\n",
    "    val_files = val_files + aug_file_dic[name][ceil(N_to_add*0.8):N_to_add]\n",
    "    #print(len([f for f in train_files_aug if name in f]))\n",
    "    #print(len([f for f in val_files_aug if name in f]))\n",
    "    \n",
    "    \n",
    "print(\"Total number of training examples : \", len(train_files))\n",
    "print(\"Total number of validation examples : \", len(val_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data loading and preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a custom dataset for the arthropod images ###\n",
    "# file_list = dataset argument : train, val or test, list of paths as strings\n",
    "\n",
    "\n",
    "class ArthropodDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, file_list, bucket_name = 'eva-arthropod', transform=None): \n",
    "        self.bucket_name = bucket_name\n",
    "        self.files = file_list\n",
    "        self.s3_resource = boto3.resource('s3')\n",
    "        self.transform = transform\n",
    "        if transform is None:\n",
    "            self.transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(size=(224, 224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        # label is infered from the filename\n",
    "        if \"imaug\" in img_name:\n",
    "            label_str = img_name[17:].split('_')[0]\n",
    "        else:\n",
    "            label_str = img_name.split('/')[1] # ex : arthropod_highres/Araneae/69e98607339f.jpg --> Araneae\n",
    "        label = int(label_dic[label_str]) # label as integer\n",
    "\n",
    "        # we need to download the file from S3 to a temporary file locally\n",
    "        # we need to create the local file name\n",
    "        obj = self.s3_resource.Object(self.bucket_name, img_name)\n",
    "        tmp_name = '/tmp/'+img_name.split('/')[-1]\n",
    "        # now we can actually download from S3 to a local place\n",
    "        with open(tmp_name, 'wb') as f:\n",
    "            obj.download_fileobj(f)\n",
    "            f.flush()\n",
    "            f.close()\n",
    "            image = Image.open(tmp_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : issue with this model is that we don't know the distribution of the IP102 dataset so we can't normalize our data with the same mean and variance than the IP102 dataset. So we have chosen to normalize the dataset with the values we have for ImageNet - at least we have an identical starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transforms  ###\n",
    "\n",
    "# train set : 224*224 images as input because min input size of mobilenet, resnet18 etc architectures \n",
    "# mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] because they are the values of the ImageNet data     \n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(224, 224)),\n",
    "    #torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# test set : same steps except the data augmentation step     \n",
    "# idem for the mean and std dev values    \n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data loaders ###\n",
    "\n",
    "train_dataset = ArthropodDataset( train_files, transform = train_transform)\n",
    "val_dataset = ArthropodDataset(val_files, transform = train_transform)\n",
    "test_dataset=ArthropodDataset(test_files, transform = test_transform)\n",
    "\n",
    "# dataloaders objects corresponding to the train and test sets\n",
    "B=16 # batch size for the data loaders\n",
    "print(\"Batch size : \", B)\n",
    "\n",
    "NUM_WORKERS = 7\n",
    "\n",
    "dl_train=torch.utils.data.DataLoader(train_dataset, batch_size=B, shuffle=True, num_workers=NUM_WORKERS) \n",
    "dl_val=torch.utils.data.DataLoader(val_dataset, batch_size=B, shuffle=True, num_workers=NUM_WORKERS)  \n",
    "dl_test=torch.utils.data.DataLoader(test_dataset, batch_size=B, shuffle=False, num_workers=NUM_WORKERS)\n",
    "print(\"Number of training batches: \",  len(dl_train))\n",
    "print(\"Number of val batches: \",  len(dl_val))\n",
    "print(\"Number of test batches: \",  len(dl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data visualization ###\n",
    "# B : batchsize = 16\n",
    "def show_images(images, labels, preds):\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = image * std + mean\n",
    "        image = np.clip(image, 0., 1.)\n",
    "        plt.imshow(image)\n",
    "        col = 'green'\n",
    "        if preds[i] != labels[i]:\n",
    "            col = 'red'            \n",
    "        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n",
    "        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "images, labels = next(iter(dl_train))\n",
    "show_images(images, labels, labels)\n",
    "\n",
    "images, labels = next(iter(dl_test))\n",
    "show_images(images, labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First runs with Resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load the pre-trained Resnet50 network__\n",
    "\n",
    "Network was pretrained on a problem consisting of 102 insect classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "boto3.resource('s3').meta.client.download_file(bucket, \n",
    "                                               os.path.join('models', 'resnet50_0.497.pkl'),\n",
    "                                               '/tmp/resnet50_wu')\n",
    "resnet_dict = torch.load('/tmp/resnet50_wu', map_location=torch.device('cpu'))\n",
    "print(\"Successfully downloaded model\")\n",
    "\n",
    "print(type(resnet_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50()\n",
    "resnet.fc = nn.Linear(in_features=resnet.fc.in_features,\n",
    "                                 out_features=102, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                                 bias=True)\n",
    "resnet.load_state_dict(resnet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "resnet.fc = nn.Linear(in_features=resnet.fc.in_features,\n",
    "                                 out_features=NUM_CLASSES, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                                 bias=True)\n",
    "resnet.to(device) # puts model on GPU / CPU\n",
    "resnet.train(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trainable parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, resnet.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Number of trainable parameters : \", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training : Transfer learning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on définit une loss et un optimizer\n",
    "# on limite l'optimisation aux paramètres de la nouvelle couche\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# test 1\n",
    "optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=0.005, momentum=0.9)\n",
    "lr_lambda = lambda epoch : 0.9991 \n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointing utils\n",
    "\n",
    "def load_checkpoint(filename='cp_ResNet', checkpoint_dir='models', bucket=bucket):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    ------\n",
    "    filename : str, choose something like cp_modelType_version_epoch\n",
    "    checkpoint_dir : str, \"/models\"\n",
    "    bucket : str, \"eva_arthropod\"\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    model_state : model state dict\n",
    "    optimizer_state : optimizer state dict\n",
    "    \"\"\"\n",
    "    boto3.resource('s3').meta.client.download_file(bucket, \n",
    "                                                   os.path.join(checkpoint_dir, filename), \n",
    "                                                   '/tmp/loaded_checkpoint')\n",
    "    model_state, optimizer_state = torch.load('/tmp/loaded_checkpoint')\n",
    "    print(\"Successfully downloaded checkpoint from s3 bucket : \" ,filename)\n",
    "    return model_state, optimizer_state \n",
    "\n",
    "def save_checkpoint(net, optimizer, filename='cp_ResNet', checkpoint_dir='models', bucket=bucket):\n",
    "    torch.save((net.state_dict(), optimizer.state_dict()), '/tmp/saved_checkpoint')\n",
    "    s3_path = os.path.join(checkpoint_dir, filename)\n",
    "    print(s3_path)\n",
    "    boto3.resource('s3').meta.client.upload_file(Filename = '/tmp/saved_checkpoint', \n",
    "                                                 Bucket = bucket, \n",
    "                                                 Key = s3_path)\n",
    "    print(\"Successfully uploaded checkpoint %s to s3 bucket under name %s.\" %(filename, s3_path))\n",
    "\n",
    "# test\n",
    "# save_checkpoint(model, optimizer)\n",
    "# load_checkpoint(filename='cp_Resnet_ft', checkpoint_dir='models', bucket=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training with checkpoints ##\n",
    "\n",
    "# learning rate decay + save checkpoint only if val accuracy was improved\n",
    "\n",
    "\n",
    "def train_v4(model, N_epochs, train_loader, test_loader, optimizer, scheduler, make_checkpoints = True, filename = 'cp_resnet', warm_start = False, warm_filename = None):\n",
    "    \"\"\"\n",
    "    model : neural network like myCNN()\n",
    "    N_epochs : int\n",
    "    train_loader : dataloader instance to iterate over training batches\n",
    "    test_loader : idem, for val or test set\n",
    "    make_checkpoints : bool\n",
    "    filename : str, filename to call whether to load checkpointed state dicts or to save a new version\n",
    "    warm_start : bool, whether to start training from scratch or from the last checkpoint\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print('Starting training..')\n",
    "    \n",
    "    if warm_start :\n",
    "        model_state, optimizer_state  = load_checkpoint(filename=warm_filename) \n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=0.01, momentum=0.9) # redefinition is necessary \n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "            \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    batch_idx_list = []\n",
    "    epoch_list = [n for n in range(N_epochs)]\n",
    "    \n",
    "    for epoch in range(N_epochs):\n",
    "        print('\\n'+'='*20+'\\nStarting epoch '+str(epoch+1) + '/'+str(N_epochs)+'\\n'+'='*20)\n",
    "        # training\n",
    "        model.train() # mode \"train\" agit sur \"dropout\" ou \"batchnorm\"\n",
    "        for batch_idx, (x, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x, target = Variable(x).to(device), Variable(target).to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if batch_idx %100 ==0:\n",
    "                print('epoch {} - batch {} [{}/{}] - training loss: {}'.format(epoch+1,batch_idx,batch_idx*len(x),\n",
    "                        len(train_loader.dataset),loss.item()))\n",
    "                train_loss_history.append(loss.item())\n",
    "                batch_idx_list.append(batch_idx+epoch*ceil(len(train_loader.dataset)/len(x))) # number of batches already processed\n",
    "                \n",
    "        # testing -- val set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x, target) in enumerate(test_loader):\n",
    "                x, target = x.to(device), target.to(device)\n",
    "                out = model(x)\n",
    "                loss = loss_fn(out, target)\n",
    "                # _, prediction = torch.max(out.data, 1)\n",
    "                prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
    "                correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        taux_classif = 100. * correct / len(test_loader.dataset)\n",
    "        print('Val Accuracy: {}/{} (i.e. {:.2f}%, error: {:.2f}%)\\n'.format(correct,\n",
    "         len(test_loader.dataset), taux_classif, 100.-taux_classif))\n",
    "        val_loss_history.append(loss.item())\n",
    "        val_acc_history.append(taux_classif)\n",
    "\n",
    "        if make_checkpoints :\n",
    "            if epoch == 0 :\n",
    "                save_checkpoint(model, optimizer, filename)                \n",
    "            elif val_acc_history[-1]>val_acc_history[-2]:\n",
    "                print(\"Improvement in validation accuracy by %s percents\" %(val_acc_history[-1]-val_acc_history[-2]))\n",
    "                save_checkpoint(model, optimizer, filename)\n",
    "            else : \n",
    "                pass\n",
    "        \n",
    "        \n",
    "    print(\"Elapsed : %s min\" %ceil((time.time()-start)/60))\n",
    "    hist_dic= {'train_loss': train_loss_history, 'epochs' : epoch_list,\n",
    "             'val_loss': val_loss_history, 'val_acc': val_acc_history, 'batches' : batch_idx_list}\n",
    "    return model, hist_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils : learning curves\n",
    "\n",
    "def plot_learning_curves(hist_dic):\n",
    "    train_loss_history, epoch_list = hist_dic['train_loss'], hist_dic['epochs'] \n",
    "    val_loss_history, val_acc_history, batch_idx_list = hist_dic['val_loss'], hist_dic['val_acc'], hist_dic['batches'] \n",
    "    # plot learning curves - training set\n",
    "    plt.plot(batch_idx_list, train_loss_history,  \n",
    "             color='blue', linestyle='dashed', \n",
    "             marker = '*', markerfacecolor='black')\n",
    "    plt.xlabel(\"Number of processed training batches\")\n",
    "    plt.ylabel(\"Training loss\")\n",
    "    plt.title('Training loss across training')\n",
    "    plt.show()\n",
    "    # plot learning curves - val set\n",
    "    plt.plot(epoch_list, val_loss_history, \n",
    "             color = 'red', linestyle = 'dashed', \n",
    "             marker = '*', markerfacecolor = 'black')\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Val loss\")\n",
    "    plt.title('Val loss across training')\n",
    "    plt.show()\n",
    "    plt.plot(epoch_list, val_acc_history,  \n",
    "             color = 'green', linestyle = 'dashed', \n",
    "             marker = '*', markerfacecolor = 'black')\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Val accuracy\")\n",
    "    plt.title('Val accuracy across training')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETTER\n",
    "\n",
    "def get_pred(model, data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    test_target= torch.LongTensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                \n",
    "            outputs = model(data)\n",
    "            pred = np.argmax(outputs,axis=1)\n",
    "            test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "            test_target = torch.cat((test_target, target), dim=0)\n",
    "        \n",
    "    return test_pred, test_target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2\n",
    "\n",
    "# Train and plot learning curves\n",
    "  \n",
    "N_epochs = 10\n",
    "optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 5e-3, 5e-5, step_size_up=2000)\n",
    "\n",
    "# model, N_epochs, train_loader, test_loader, make_checkpoints = True, filename = 'cp_MobileNet', warm_start = False    \n",
    "trained_model, hist_dic = train_v4(resnet, N_epochs, dl_train, dl_val, optimizer, scheduler, \n",
    "                                   filename = 'cp_Resnet_transfered_aug', warm_start = False)\n",
    "\n",
    "# plot learning curves\n",
    "plot_learning_curves(hist_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, train_target = get_pred(model, dl_train)\n",
    "val_pred, val_target = get_pred(model, dl_val)\n",
    "\n",
    "print(\"\\nPerformance on training set\")\n",
    "print(classification_report(train_target, train_pred, target_names=class_names))\n",
    "print(\"\\nPerformance on val set\")\n",
    "print(classification_report(val_target, val_pred, target_names=class_names))\n",
    "\n",
    "test_pred, test_target = get_pred(trained_model, dl_test)\n",
    "print(\"\\nPerformance on test set\")\n",
    "print(classification_report(test_target, test_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reload pretrained model__\n",
    "\n",
    "This time we want to learn the parameters of the entire network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize resnet\n",
    "resnet_ft = models.resnet50()\n",
    "resnet_ft.fc = nn.Linear(in_features=resnet_ft.fc.in_features,\n",
    "                         out_features=102, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                         bias=True)\n",
    "resnet_ft.load_state_dict(resnet_dict)\n",
    "resnet_ft.to(device)\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "resnet_ft.fc = nn.Linear(in_features=resnet_ft.fc.in_features,\n",
    "                                 out_features=NUM_CLASSES, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                                 bias=True)\n",
    "resnet_ft.to(device) # puts model on GPU / CPU\n",
    "resnet_ft.train(True) \n",
    "\n",
    "params_to_update = resnet_ft.parameters()\n",
    "\n",
    "# number of trainable parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, resnet_ft.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Number of trainable parameters : \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ré-entraîne\n",
    "print(\"Fine-tuning of ResNet50 by Wu\")\n",
    "resnet_ft.train(True)\n",
    "\n",
    "trained_model_ft, hist_dic_ft = train_v4(resnet_ft, 5, dl_train, dl_val,  filename = 'cp_Resnet_ft', warm_start = False)\n",
    "plot_learning_curves(hist_dic_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "filename = 'resnetWu_finetuned_1.pth'\n",
    "torch.save(trained_model_ft.state_dict(), filename)\n",
    "print(\"saved model to {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_pred, test_target = get_pred(trained_model, dl_test)\n",
    "print(\"\\nPerformance on test set\")\n",
    "print(classification_report(test_target, test_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data loaders ###\n",
    "\n",
    "def load_data(train_files, val_files, test_files):\n",
    "\n",
    "    # train set : 224*224 images as input because min input size of mobilenet, resnet18 etc architectures \n",
    "    # mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] because they are the values of the ImageNet data     \n",
    "    train_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size=(224, 224)),\n",
    "        #torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # test set : same steps except the data augmentation step     \n",
    "    # idem for the mean and std dev values    \n",
    "    test_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size=(224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = ArthropodDataset(train_files, transform = train_transform)\n",
    "    val_dataset = ArthropodDataset(val_files, transform = train_transform)\n",
    "    test_dataset=ArthropodDataset(test_files, transform = test_transform)\n",
    "\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# test OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search space ###\n",
    "\n",
    "N_epochs = 8\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "config = {            \n",
    "            \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "            \"batch_size\": tune.choice([4, 8, 16])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Transfered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize resnet\n",
    "\n",
    "resnet = models.resnet50()\n",
    "resnet.fc = nn.Linear(in_features=resnet.fc.in_features,\n",
    "                      out_features=102, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                      bias=True)\n",
    "resnet.load_state_dict(resnet_dict)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "resnet.fc = nn.Linear(in_features=resnet.fc.in_features,\n",
    "                      out_features=NUM_CLASSES, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                      bias=True)\n",
    "resnet.to(device) # puts model on GPU / CPU\n",
    "resnet.train(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training ###\n",
    "\n",
    "# with multiplicative learning rate decay  \n",
    "# and checkpointing \n",
    "\n",
    "def train_n_tune(config, checkpoint_dir=None): # config, N_epochs, train_files, val_files, test_files, \n",
    "    \n",
    "    net = resnet\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer =  torch.optim.SGD(net.parameters(), lr=config[\"lr\"]) ## To adapt ##\n",
    "    lr_lambda = lambda x : 0.9991 \n",
    "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)\n",
    "\n",
    "    if checkpoint_dir:    \n",
    "        model_state, optimizer_state = load_checkpoint('cp_Resnet_transfered')    # to test                    \n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    train_subset, val_subset, testset = load_data(train_files, val_files, test_files)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=2)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=2)\n",
    "\n",
    "    def test_accuracy(net, device=\"cpu\"): # train_files, val_files, test_files are global \n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return correct / total\n",
    "    \n",
    "    for epoch in range(N_epochs):  # loop over the dataset multiple times\n",
    "        print(\"--- Epoch %s ---\" %(epoch+1))\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            try :\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                epoch_steps += 1\n",
    "                if i % 200 == 199:  # print every 200 mini-batches\n",
    "                    print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                    running_loss / epoch_steps))\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            except : \n",
    "                print(\"Batch number %s left out / Training (OSError : missing bytes)\" %i)\n",
    "                # OSError: image file is truncated (X bytes not processed)\n",
    "        print(\"Average loss for epoch %s : %s\" %(epoch+1, running_loss/epoch_steps))\n",
    "        \n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            try :\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = net(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.cpu().numpy()\n",
    "                    val_steps += 1\n",
    "            except :\n",
    "                print(\"Batch number %s left out / Validation (OSError : missing bytes)\" %i)\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    test_acc = test_accuracy(net, device)\n",
    "    print(\"Current test set accuracy: {}\".format(test_acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main : perform hp tuning ###\n",
    "\n",
    "# train_files, val_files, test_files,  already defined above \n",
    "\n",
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = load_data(train_files, val_files, test_files)\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    \n",
    "    result = tune.run(\n",
    "        partial(train_n_tune), # config=config, N_epochs=max_num_epochs, train_files, val_files, test_files\n",
    "        resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = models.resnet50(pretrained=True)\n",
    "    best_trained_model.fc = nn.Linear(in_features=best_trained_model.fc.in_features, \n",
    "                                                 out_features=NUM_CLASSES, bias=True)\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "    \n",
    "    def test_accuracy(net, device=\"cpu\"): # train_files, val_files, test_files are global \n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return correct / total\n",
    "    \n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(num_samples=6, max_num_epochs=10, gpus_per_trial=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fine-tuned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize resnet\n",
    "\n",
    "resnet = models.resnet50()\n",
    "resnet.fc = nn.Linear(in_features=resnet.fc.in_features,\n",
    "                      out_features=102, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                      bias=True)\n",
    "resnet.load_state_dict(resnet_dict)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True # this time we want to learn all parameters\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "resnet.fc = nn.Linear(in_features=resnet.fc.in_features,\n",
    "                      out_features=NUM_CLASSES, # Wu et al. trained their models on a dataset with 102 classes\n",
    "                      bias=True)\n",
    "resnet.to(device) # puts model on GPU / CPU\n",
    "resnet.train(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again main, this time the newly created resnet version is called\n",
    "main(num_samples=6, max_num_epochs=10, gpus_per_trial=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
